"""Utility functions for logging, text processing, and help display."""

import csv
import os
from datetime import datetime

def log_performance(model_name, transcription_time, text_length, audio_duration, enhancement_time=None):
    """Log performance metrics to a CSV file.
    
    Args:
        model_name (str): Name of the Whisper model used.
        transcription_time (float): Time taken to transcribe in seconds.
        text_length (int): Length of the transcribed text in characters.
        audio_duration (float): Duration of the audio in seconds.
        enhancement_time (float, optional): Time taken for LLM enhancement in seconds.
    """
    log_file = "transcription_performance.csv"
    file_exists = os.path.exists(log_file)
    
    with open(log_file, 'a', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['timestamp', 'model', 'transcription_time_ms', 'text_length', 'audio_duration_ms', 'time_per_char_ms', 'realtime_factor', 'enhancement_time_ms']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # Write header if file is new
        if not file_exists:
            writer.writeheader()
        
        time_per_char = transcription_time / text_length if text_length > 0 else 0
        realtime_factor = transcription_time / audio_duration if audio_duration > 0 else 0
        
        writer.writerow({
            'timestamp': datetime.now().isoformat(),
            'model': model_name,
            'transcription_time_ms': round(transcription_time * 1000, 2),
            'text_length': text_length,
            'audio_duration_ms': round(audio_duration * 1000, 2),
            'time_per_char_ms': round(time_per_char * 1000, 4),
            'realtime_factor': round(realtime_factor, 3),
            'enhancement_time_ms': round(enhancement_time * 1000, 2) if enhancement_time is not None else 'None'
        })

def post_process_transcription(text):
    """Post-process transcribed text by cleaning and formatting it.
    
    Args:
        text (str): Raw transcribed text from Whisper.
        
    Returns:
        str: Cleaned and formatted text, or empty string if no valid text.
    """
    # Strip whitespace
    text = text.strip()
    
    # Return empty string if no text
    if not text:
        return ""
    
    # Capitalize the first letter
    text = text[0].upper() + text[1:]
    
    return text

def show_help():
    """Display help information about available Whisper models and usage."""
    help_text = """
üé§ TYNI-WISPR: Real-time Speech-to-Text using Whisper
=====================================================

USAGE:
    python tyni-wispr.py [OPTIONS]

ARGUMENTS:
    --model, -m              Whisper model to use (default: turbo)
    --log-performance, -l    Enable performance logging to CSV file
    --silent, -s             Suppress startup and completion log messages
    --llm-enhance, -e        Enable LLM text enhancement via Ollama
    --ollama-model           Ollama model to use for enhancement (default: gemma3:12b)
    --ollama-url             Ollama server URL and port (default: http://localhost:11434)
    --help, -h               Show this help message and exit

HOW TO USE:
    1. Run the script: python tyni-wispr.py
    2. Press and hold the right shift key to start recording
    3. Release the right shift key to stop recording
    4. Audio is transcribed using Whisper model
    5. Text is optionally enhanced with LLM (if --llm-enhance is enabled)
    6. Final text is automatically typed in the active window

WORKFLOW:
    Recording ‚Üí Whisper Transcription ‚Üí [LLM Enhancement] ‚Üí Text Output

AVAILABLE WHISPER MODELS:
==========================

üèÉ TINY MODELS (39M parameters, ~150MB)
    ‚Ä¢ tiny     - Multilingual, fastest speed (10x vs large), lowest accuracy
    ‚Ä¢ tiny.en  - English-only variant, optimized for English content
    Best for: Quick transcriptions, limited resources, clear audio with minimal noise

‚ö° BASE MODELS (74M parameters, ~300MB) 
    ‚Ä¢ base     - Multilingual, good balance for limited resources (7x vs large)
    ‚Ä¢ base.en  - English-only variant, better performance on English
    Best for: General purpose transcription with reasonable accuracy when resources are limited

üöÄ SMALL MODELS (244M parameters, ~1GB)
    ‚Ä¢ small    - Multilingual, recommended for most use cases (4x vs large)
    ‚Ä¢ small.en - English-only variant, more efficient for English content
    Best for: Daily transcription needs with good accuracy and reasonable speed

üéØ MEDIUM MODELS (769M parameters, ~3GB)
    ‚Ä¢ medium   - Multilingual, high accuracy (2x vs large)
    ‚Ä¢ medium.en- English-only variant, optimized for English
    Best for: High-quality transcriptions where accuracy is important

üî• LARGE MODELS (1.5B parameters, ~6GB)
    ‚Ä¢ large-v1 - Original large model
    ‚Ä¢ large-v2 - Improved large model  
    ‚Ä¢ large-v3 - Latest large model with best accuracy
    ‚Ä¢ large    - Alias for latest large model
    Best for: Professional transcription where maximum accuracy is essential

‚ö° ADVANCED MODELS
    ‚Ä¢ turbo    - Optimized for speed while maintaining accuracy (RECOMMENDED)

SELECTION TIPS:
===============
    ‚Ä¢ For English-only: Use .en variants for better performance and efficiency
    ‚Ä¢ For multilingual: Use standard models (support 100+ languages)
    ‚Ä¢ CPU-only systems: Stick to tiny/base models
    ‚Ä¢ Consumer GPUs: small/medium models work well
    ‚Ä¢ High-end GPUs: can efficiently run large models
    ‚Ä¢ Clear audio: Smaller models may be sufficient
    ‚Ä¢ Challenging audio (noise/accents): Use larger models

EXAMPLES:
=========
    python tyni-wispr.py                         # Use default turbo model
    python tyni-wispr.py --model small.en        # Use small English-only model
    python tyni-wispr.py -m tiny                 # Use tiny multilingual model
    python tyni-wispr.py --log-performance       # Enable performance logging
    python tyni-wispr.py -m turbo -l             # Use turbo model with logging
    python tyni-wispr.py --llm-enhance           # Enable LLM text enhancement    python tyni-wispr.py -e --ollama-model llama3:8b  # Use different LLM model
    python tyni-wispr.py --ollama-url http://192.168.1.100:11434  # Use remote Ollama server
    python tyni-wispr.py -e --ollama-url http://localhost:8080 --ollama-model llama3:8b  # Custom URL and model
    python tyni-wispr.py -m small.en -l -e -s    # Compact mode with all features
    python tyni-wispr.py --silent                # Suppress console output
    python tyni-wispr.py --help                  # Show this help

LLM ENHANCEMENT:
================
    ‚Ä¢ Requires Ollama running locally (default: http://localhost:11434) or remotely
    ‚Ä¢ Use --ollama-url to specify custom Ollama server URL and port
    ‚Ä¢ Improves punctuation, grammar, and text clarity
    ‚Ä¢ Adds processing time but enhances accuracy
    ‚Ä¢ Use --ollama-model to specify different models
    ‚Ä¢ Install Ollama models with: ollama pull MODEL_NAME

REQUIREMENTS:
=============
    ‚Ä¢ Python 3.7+
    ‚Ä¢ PyTorch with CUDA support (optional, for GPU acceleration)
    ‚Ä¢ Microphone access
    ‚Ä¢ Required packages: whisper, torch, sounddevice, numpy, pyautogui, keyboard, requests
    ‚Ä¢ Ollama (optional, for LLM text enhancement)
"""
    print(help_text)
